---
title: "DataCleaningDocumentation"
author: "Chad Crowe"
date: "10/12/2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(moderndive)
```

## Job Position, Ethnicity, Location, and Dropped Appointments

### RQ Overview

The third research question concerns exploring the job role of therapists within HFS, with specific interest in appoinment no shows. When patients fail to appear for appointments, this costs HFS time and costs the patient opportunity for therapy. We explore whether there exist clear patterns that might contribute to patients missing visits, such as a location or ethnicity effect. It might be the case that particular facilities are less friendly in supporting a language, which might effect the rate of dropped appointments. 

The research also explores whether job title effects dropped appointments. Job requirements might change from title to title that might have an effect on dropped appointments. This research explores the phenomenon. 

Initial research also explores appointment duration.  Based on the given data, it is unknown whether appointment duration is fixed by insurance or varies between patients. This research explores duration of appointments across job position, ethnicity, location, and the rate of dropped appointments too. While success is not determined by duration, Dr. Juarez mentioned how HFS is very interested in exploring patterns pertaining to the number of appointments and durations by each patient since it affects the funding HFS receives. 

### Datasets Used

The data explored in this research question include five columns:

- Job Title (Therapists I, II, and III)

- Ethnicity

- Facility Location

- Appointment Duration

- Appointment No Shows

Each column will be explored in the following section. The section will describe the number of rows & columns and provide sample headers. The section will also include a description of the metadata, such as what information is available for understanding and interpreting the data. The section will also cover the rationale for remediating and cleaning the data, such as handling empty data. It will also include a description of the approach and the code required for replication.

### Description of Datasets

#### Job Title (Therapists I, II, and III)

```{r classwork}
data <- read.csv("/Users/ccrowe/github/isqa8600_ChadCrowe/programs/data/HFS Service Data.csv")
```
The data contains `r nrow(data)` rows. If we filter out NA values for job title there are `r nrow(as_tibble(data) %>% drop_na(job_title))`. This means each row has a job title and there are no NA values. Given that there is no missing data, there is no need to handle missing data. 

Below is a plot of available job titles:
```{r job_title_all}
tibble_data <- as_tibble(data)
# data header
head(tibble_data$job_title)
job_title_counts <- tibble_data %>% group_by(job_title) %>% count(sort=TRUE)
ggplot(job_title_counts) + geom_point(mapping = aes(x = reorder(job_title,-n), y = n)) +
ggtitle("Count of Rows for each Job Title") +
xlab("Job Title") +
ylab("Count of Job Title's Occurrence") +
 #ylim(0, 130) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")

```

Most job titles have fewer than fifty instances. Job titles with many instances include therapist, clinical supervisor, case managers, and admin assists. Of those job titles, there are five types of therapists. Given most of the primary job titles are therapists, the exploration of job titles will focus on therapists. We filter the job titles to the various therapist job positions.

```{r filter_for_therapists}
therapists = data %>% filter(data$job_title == "THERAPIST I" | data$job_title == "THERAPIST II" | data$job_title == "THERAPIST III" | data$job_title == "LEAD THERAPIST" | data$job_title == "Therapist")
```

If we filter out therapists there are only `r nrow(therapists)` rows, so 1500 fewer rows. 

#### Ethnicity

```{r ethnicity_breakdown}
tibble_data <- as_tibble(data)
ethnicity <- tibble_data %>% group_by(ethnic_identity) %>% count(sort=TRUE)
# data header
head(tibble_data$ethnic_identity)

```

There are no NAs for the ethnic_identity column. The ethnic identities are categorized as Mexian, Hispanic/Latino, and not Spanish/Hispanic/Latino. Ninety-percent of the data (7820 rows) are not Spanish, Hispanic or Latino. The following plot shows the diparity of counts within the ethic_identity column.

```{r ethnic_plot}
ggplot(ethnicity) + geom_point(mapping = aes(x = reorder(ethnic_identity,-n), y = n)) +
ggtitle("Count of Rows for each Ethnicity") +
xlab("Ethnicity") +
ylab("Count of Ethnicity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
```

Given that most categories have fewer than two-hundred persons, one simlification is to create a binary column for Not Spanish/Hispanic/Latino and Spanish/Hispanic/Lantino.  We'll filter out unknown since it contains no ethnic identity information. Otherwise, there are no NAs or missing data in this column so there's no need to handle or filter out NAs.

```{r two_ethnicities}
two_ethnicities <- tibble_data %>% mutate(is_minority = ethnic_identity != "Not Spanish/Hispanic/Latino") %>% filter(ethnic_identity != "Unknown")
two_ethnicities %>% group_by(is_minority) %>% count()
```

When we filter by the identified ethinicities and filter out the unknown category we get almost 800 rows of ethnicities HFS tracks. 


#### Facility Location

Below we can see a breakdown of records per facility.  We group by facility and sort by the facilities with the most usage. This will help us understand the usage of HFS facilities within the dataset.

```{r facility_breakdown}
tibble_data <- as_tibble(data)
# data header
head(tibble_data$facility)
grouped_facility <- tibble_data %>% group_by(facility) %>% count(sort=TRUE)
#ordered <- transform(grouped_facility, variable=reorder(facility, n) ) 
ggplot(grouped_facility) + geom_point(mapping = aes(x = reorder(facility,-n), y = n)) +
ggtitle("Count of Records by Facility") +
xlab("Facility") +
ylab("Count of Records at a Facility") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
# check for NAs
tibble_data %>% filter(facility == NA) %>% count()
```

From the graph we see nine main facilities with more than two-hundred records. There are three facilities with more than one-thousand rows. We want to avoid aggregating smaller facilities together since each facility might be very different.  For now, we will leave the smaller facilities in the data.  Later on, we might remove facilities with very few users. No rows are NA so there is no need to handle NAs or missing data in this column. 

#### Appointment No Shows

The column is_noshow is interesting because these are costly events for both HFS and for the potential benefactor. No_shows consume HFS appointment time and the person loses out on an opportunity for therapy. 

```{r noshow_breakdown}
tibble_data <- as_tibble(data)
# data header
head(tibble_data$is_noshow)
grouped_no_show <- tibble_data %>% group_by(is_noshow) %>% count(sort=TRUE)
ggplot(grouped_no_show) + geom_point(mapping = aes(x = reorder(is_noshow,-n), y = n)) +
ggtitle("Count of Rows for Show vs NoShow") +
xlab("Appointment Show or No Show") +
ylab("Count of Category") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none")
# check for NAs
tibble_data %>% filter(is_noshow == NA) %>% count()
```

We see that 15% of all rows are no shows. 15% seems like a surprisingly high number of appointment no shows for any organization. This metric is worth looking into further. There are no NAs in the column or values we want to filter.

### Number of Appointments per Person

HFS has voiced an interest in the number of appointments and total duration spent per patient. While duration length or the number of appointments does not connotate to organizational success, they are metrics that HFS reports to funders. 

```{r appointments}
tibble_data <- as_tibble(data)
# data header
head(tibble_data$recordID)
record_counts <- tibble_data %>% group_by(recordID) %>% count(sort=TRUE) %>% filter(n > 2)
ggplot(record_counts) + geom_point(mapping = aes(x = reorder(recordID,-n), y = n)) +
ggtitle("Plot of Repeated Record Count per Person") +
xlab("Person's RecordId") +
ylab("Count of Person's Appointments") +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

There are only 460 records with more than one appointment with HFS, which is only 5% of all HFS records. From this we learn that almost all appointments are single-time appointments. Considering the few number of records with multiple appointments, it might not be worth looking further into the factors affecting duration or the number of appointments.







1-2 paragraph text description of the data source/s (how much, where from, what it contains, etc.) with a properly formatted citation for each data source. This should include how many rows & columns (&/or tables) and sample column headers. Each data source you're using should have a similar description.
Specifically identify any intellectual policy constraints, or lack thereof (licensing).
1 paragraph description of the metadata: what information is available to help you interpret and understand the data?
Identify any issues you have encountered with the data: missing values, unstandardized content, entity matching, integration, etc.
1 paragraph description of your rationale for the steps you're taking to remediate data. For example, if you need to fill in empty fields, specify what value you chose and why.
A script or step-by-step textual description (or a combination) that documents your data cleaning process with enough detail for replication.
A contributorship statement.
This deliverable supports timely feedback for work-in-progress. Any issues highlighted by instructor feedback should be carefully addressed in your final project data processing documentation. Submit a knitted HTML document that provides an overview of the script, along with the contributorship statement, with the URL submitted on Canvas; update the Readme.md with the document link. The source RMarkdown document must include the full script in the same deliverable directory. If you are not yet able to do your full data cleaning procedures in R, describe any additional step-by-step processes in fine detail within the document.



